{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Carlos Gross-Martinez**\n",
        "\n",
        "#**Assignmnet 2 - Elastic Net**\n",
        "\n",
        "#**CAP6640 - Computational Foundations of AI**\n",
        "\n"
      ],
      "metadata": {
        "id": "RVAzoH-E6n9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Importing libraries to use in the program and importing the information from the excel sheet to create a data frame for data manipulation and processing. Then, updating values from qualitative to quatitave for features that need to be updated. Finally, printing the dataframe to verify information.***"
      ],
      "metadata": {
        "id": "YTpnMVMT6wcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_import = pd.read_csv(\"Credit_N400_p9.csv\")\n",
        "updated_data_import = data_import.replace({'Gender':{'Male': 1, 'Female': 0}, 'Student':{'Yes': 1, 'No': 0}, 'Married':{'Yes': 1, 'No': 0}}) \n",
        "\n",
        "updated_data_import"
      ],
      "metadata": {
        "id": "NaWVrW4Og8Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Converting pd dataframe into np array for manipulation. Next, centering and standarizing the features. Then, centering the output. Finally, creating X and y matrices for elastic net training and printing results to screen to verify information***"
      ],
      "metadata": {
        "id": "r-xjcMqz7OXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = updated_data_import.to_numpy()\n",
        "\n",
        "y = 0\n",
        "X = []\n",
        "\n",
        "for feature in range(data_set.shape[1]):\n",
        "\n",
        "  if feature == data_set.shape[1] - 1:\n",
        "    y = np.subtract(data_set[:, feature], np.mean(data_set[:, feature]))\n",
        "  else:\n",
        "    X.append(np.divide(np.subtract(data_set[:, feature], np.mean(data_set[:, feature])), np.std(data_set[:, feature])))\n",
        "\n",
        "X = np.asarray(X)\n",
        "X = X.T\n",
        "\n",
        "print(type(y))\n",
        "print(y.shape)\n",
        "print(y)\n",
        "print(type(X))\n",
        "print(X.shape)\n",
        "print(X)"
      ],
      "metadata": {
        "id": "uqOzoKHElpHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Defining the class elastic regression that will conduct elastic net using coordinate descent in the dataset. It will loop through different tunning parameters and return the beta values for all tunning parameters in an array.***"
      ],
      "metadata": {
        "id": "AgO3pFqlBbgZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3FI8Ouje2Rg"
      },
      "source": [
        "class ElasticRegression() :\n",
        "    def __init__( self, learning_rate, iterations, tuningParam1, tuningParam2) :\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.tuningParam1 = tuningParam1\n",
        "        self.tuningParam2 = tuningParam2\n",
        "\n",
        "    def fit( self, X, Y ) :\n",
        "        self.exampleNum, self.ftnum = X.shape\n",
        "        self.W = np.random.uniform(-1, 1, 9)\n",
        "        self.b = 0 \n",
        "        self.X = X \n",
        "        self.Y = Y \n",
        "\n",
        "        for i in range( self.iterations ) :   \n",
        "            self.update_weights()\n",
        "        return self\n",
        "      \n",
        "    def update_weights( self ) :\n",
        "        Y_pred = self.predict( self.X )\n",
        "        dW = np.random.uniform(-1, 1, 9)\n",
        "        for j in range( self.ftnum ) : \n",
        "            if self.W[j] > 0 :  \n",
        "                dW[j] = ( - ( 2 * ( self.X[:,j] ).dot( self.Y - Y_pred ) ) +          \n",
        "                         self.tuningParam1 + 2 * self.tuningParam2 * self.W[j] ) / self.exampleNum\n",
        "            else :\n",
        "                dW[j] = ( - ( 2 * ( self.X[:,j] ).dot( self.Y - Y_pred ) )      \n",
        "                         - self.tuningParam1 + 2 * self.tuningParam2 * self.W[j] ) / self.exampleNum\n",
        "        db = - 2 * np.sum( self.Y - Y_pred ) / self.exampleNum\n",
        "        self.W = self.W - self.learning_rate * dW\n",
        "        self.b = self.b - self.learning_rate * db\n",
        "        return self\n",
        "\n",
        "    def predict( self, X ) :\n",
        "        return X.dot( self.W ) + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Driver program to obtain coeficients from elastic net training. It will loop through all tunning parameters (alphas and lamdas) to calaculate best beta values***"
      ],
      "metadata": {
        "id": "i3KoLPznVk95"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKU0X6AQe2T0"
      },
      "source": [
        "#9 Features plot of coefficients.\n",
        "Tuning_parameters = [10**-2,10**-1,10**0,10**1,10**2,10**3,10**4, 10**5, 10**6]\n",
        "Tuning_parameters2 = [0,1/5,2/5,3/5,4/5,1]\n",
        "lr = 10**-5\n",
        "iteration = 1000\n",
        "\n",
        "coef = []\n",
        "\n",
        "for tuningParameter in Tuning_parameters:\n",
        "  nineParams = []\n",
        "  for tuningParameter2 in Tuning_parameters2:\n",
        "    elastic = ElasticRegression(lr,iteration,tuningParameter2,tuningParameter)\n",
        "    elastic.fit(X,y)\n",
        "    nineParams.append(elastic.W)\n",
        "  coef.append(nineParams)\n",
        "print(coef)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Deliverable 1***"
      ],
      "metadata": {
        "id": "kzttVnOIV7rV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Plotting all 6 graphs with the lambdas for each alpha***"
      ],
      "metadata": {
        "id": "O0BOL-dcWEHH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LjuMQ4de2V6"
      },
      "source": [
        "#Deliverable 1\n",
        "import matplotlib.pyplot as plt\n",
        "pltfeatures = ['Income','Limit','Rating','Cards','Age','Education','Gender','Student','Married']\n",
        "\n",
        "for x in range(0,6):\n",
        "  Income = []\n",
        "  Limit = []\n",
        "  Rating = []\n",
        "  Cards = []\n",
        "  Age = []\n",
        "  Education = []\n",
        "  Gender = []\n",
        "  Student = []\n",
        "  Married = []\n",
        "  for i in range(0,9):\n",
        "    Income.append(coef[i][x][0])\n",
        "    Limit.append(coef[i][x][1])\n",
        "    Rating.append(coef[i][x][2])\n",
        "    Cards.append(coef[i][x][3])\n",
        "    Age.append(coef[i][x][4])\n",
        "    Education.append(coef[i][x][5])\n",
        "    Gender.append(coef[i][x][6])\n",
        "    Student.append(coef[i][x][7])\n",
        "    Married.append(coef[i][x][8])\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.xscale('log')\n",
        "  plt.title(str(Tuning_parameters2[x]) +\" tuning parameter\")\n",
        "  ax.plot(Tuning_parameters,Income,label=\"Income\")\n",
        "  ax.plot(Tuning_parameters,Limit,label=\"Limit\")\n",
        "  ax.plot(Tuning_parameters,Rating,label=\"Rating\")\n",
        "  ax.plot(Tuning_parameters,Cards,label=\"Cards\")\n",
        "  ax.plot(Tuning_parameters,Age,label=\"Age\")\n",
        "  ax.plot(Tuning_parameters,Education,label=\"Education\")\n",
        "  ax.plot(Tuning_parameters,Gender,label=\"Gender\")\n",
        "  ax.plot(Tuning_parameters,Student,label=\"Student\")\n",
        "  ax.plot(Tuning_parameters,Married,label=\"Married\")\n",
        "  ax.legend(loc = 'upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Defining a function to split a datasets into folds. The function takes the datasets X and y as well as a fold number which will split the data set and return the partitioned dataset***"
      ],
      "metadata": {
        "id": "3DmGuNQI8myI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVzaXm25e2PO"
      },
      "source": [
        "from random import randrange\n",
        "\n",
        "def cross_val_split(x,y, folds):\n",
        "\tfeatures = []\n",
        "\tlabels = []\n",
        "\tx_copy = list(x)\n",
        "\ty_copy = list(y)\n",
        "\tfold_size = int(len(x) / folds)\n",
        "\tfor i in range(folds):\n",
        "\t\tx_fold = []\n",
        "\t\ty_fold = []\n",
        "\t\twhile len(x_fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(x_copy))\n",
        "\t\t\tx_fold.append(x_copy.pop(index))\n",
        "\t\t\ty_fold.append(y_copy.pop(index))\n",
        "\t\tfeatures.append(x_fold)\n",
        "\t\tlabels.append(y_fold)\n",
        "\treturn features,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Training model with cross validations and calculating MSE results for plotting***"
      ],
      "metadata": {
        "id": "NBVAhIyvWjSm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG-IZwo8e2YC"
      },
      "source": [
        "#Training the model using Cross Validation\n",
        "Tuning_parameters = [10**-2,10**-1,10**0,10**1,10**2,10**3,10**4, 10**5, 10**6]\n",
        "Tuning_parameters2 = [0,1/5,2/5,3/5,4/5,1]\n",
        "lr = 10**-5\n",
        "iteration = 1000\n",
        "fold_num = 5\n",
        "\n",
        "ft,lb= cross_val_split(X,y,5)\n",
        "\n",
        "finalResults = []\n",
        "for tuningParameter2 in Tuning_parameters2:\n",
        "  mseResults = []\n",
        "  for tuningParameter in Tuning_parameters:\n",
        "    model = ElasticRegression(lr,iteration,tuningParameter2,tuningParameter)\n",
        "    foldMSE = []\n",
        "    for i in range(0,fold_num):\n",
        "\n",
        "      valx = ft[i]\n",
        "      valy = lb[i]\n",
        "      trainx = []\n",
        "      trainy = []\n",
        "      for x in range (0,fold_num):\n",
        "        if x != i:\n",
        "          trainx += ft[x]\n",
        "          trainy += lb[x]\n",
        "      trainx = np.array(trainx)\n",
        "      trainy = np.array(trainy)\n",
        "      valx = np.array(valx)\n",
        "      valy = np.array(valy)\n",
        "\n",
        "      model.fit(trainx,trainy)\n",
        "      prediction = model.predict(valx)\n",
        "      n = len(valy)\n",
        "\n",
        "      squaredError = ((valy - prediction) ** 2)\n",
        "      error = np.mean(squaredError)\n",
        "\n",
        "      foldMSE.append(error)\n",
        "\n",
        "    meanFoldMSE = np.mean(foldMSE)\n",
        "    mseResults.append(meanFoldMSE)\n",
        "  finalResults.append(mseResults)\n",
        "print(finalResults)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Deliverable 2***"
      ],
      "metadata": {
        "id": "AnbJJu49W0c0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Plotting all MSe values obtained from cross validation based on each alpha value***"
      ],
      "metadata": {
        "id": "gEzqOhmjW2CM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXdIRz8ce2Z_"
      },
      "source": [
        "#Deliverable 2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "count = 0\n",
        "for mse in finalResults:\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.xscale('log')\n",
        "  plt.plot(Tuning_parameters, mse)\n",
        "  ax.set_ylabel(\"MSE\")\n",
        "  ax.set_xlabel('\\u03BB')\n",
        "  ax.set_title( str(count) +' alpha 5 CV Tuning Parameters')\n",
        "  plt.show()\n",
        "  count += 0.2\n",
        "  count = round(count, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Deliverable 3***"
      ],
      "metadata": {
        "id": "0hyq-357XBeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Obtaining the pair of values for lambda and alpha that provides the lowest MSE error***"
      ],
      "metadata": {
        "id": "PSm7mkT5XGYB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX_XVnA4e2cE"
      },
      "source": [
        "mins = []\n",
        "minindexes = []\n",
        "mintuns = []\n",
        "mintuns2 = []\n",
        "for mse in finalResults:\n",
        "  minCVError = min(mse)\n",
        "  minCVIndex = mse.index(minCVError)\n",
        "  ðœ† = Tuning_parameters[minCVIndex]\n",
        "  Î± = Tuning_parameters2[minCVIndex]\n",
        "  mins.append(minCVError)\n",
        "  mintuns.append(ðœ†)\n",
        "  mintuns2.append(Î±)\n",
        "\n",
        "finalMin = min(mins)\n",
        "minÎ± = mins.index(finalMin)\n",
        "\n",
        "for mse in finalResults:\n",
        "  if finalMin in mse:\n",
        "    minðœ† = mse.index(finalMin)\n",
        "\n",
        "print(\"Optimal Î±: \", Tuning_parameters2[minÎ±])\n",
        "print(\"Optimal ðœ†: \", Tuning_parameters[minðœ†])\n",
        "print(\"Minimum CV(5) error: \", finalResults[minÎ±][minðœ†])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Deliverable 4***"
      ],
      "metadata": {
        "id": "_N7gtn4KXan0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Retraining the model with the lamda and alpha values provided the lowest MSE, and printing the beta values obtained from the traning***"
      ],
      "metadata": {
        "id": "-i6UCAVLXeOe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y8d0bTde2eN"
      },
      "source": [
        "optimalLamda = minðœ†\n",
        "optimalAlpha = minÎ±\n",
        "lr = 10**-5\n",
        "iteration = 10000\n",
        "coef = []\n",
        "\n",
        "elastic = ElasticRegression(lr,iteration,optimalLamda,optimalAlpha)\n",
        "elastic.fit(X,y)\n",
        "coef = elastic.W\n",
        "print(\"Best Beta Estimate:\", coef)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}